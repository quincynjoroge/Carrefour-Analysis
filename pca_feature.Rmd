---
title: "Supermarket"
author: "Quincy"
date: "9/9/2021"
output:
  pdf_document: default
  html_document: default
---
# SUPERMAKET ANALYSIS

## CONTEXT
Carrefour is a retail-focused global corporation based in France. It has operations in a number of countries, including the United Arab Emirates, Australia, Brazil, and, closer to home, Kenya.

As a data analyst at Carrefour Kenya, I'm now working on a project to tell the marketing department about the most effective marketing methods for generating the greatest sales (total price including tax).

## EXPERIMENTAL DESIGN

The project is separated into four sections, each of which examines a recent marketing dataset using a variety of unsupervised learning approaches before making suggestions based on your findings.

Part 1: Reducing Dimensionality

PCA is used to reduce the dataset to a low-dimensional dataset in this section of the research.

Part 2: Choosing Features

This part calls on you to apply unsupervised learning methods to perform feature selection.

Association Rules (Part 3)

This section will require you to develop association rules in order to identify relationships between variables in the dataset.

Part 4: Detecting Anomalies

We will check if there are any.

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Load data
```{r}
# Loading our data
supermarket = read.csv("http://bit.ly/CarreFourDataset")
```

```{r}
# Viewing the top of our data
head(supermarket)
```
```{r}
# Viewing the bottom of our data
tail(supermarket)
```

```{r}
# checking the shape of our data
dim(supermarket)
```

Our data has 1000 observations and 16 variables.

```{r}
# checking the structure of our data
str(supermarket)
```

Our data has 16 character variables and 8 numerical variables.

### Data cleaning

```{r}
# checking for missing values
colSums(is.na(supermarket))
```

Our dataset has no missing values.

```{r}
# checking for duplicate values
colSums(supermarket[duplicated(supermarket),])
```

Our data set has no duplicate values.

```{r}
# lower case of the column names
names(supermarket) <- tolower(names(supermarket))
names(supermarket)
```

Our column names have been lowered for easier manipulation.

```{r}
# checking for outliers
# detect outliers by use ofsome descriptive statistics, 
# and in particular with the minimum and maximum.
summary(supermarket)
```

According to the summary data, no outliers are present. We will, however, continue to look into the matter in order to assess and confirm our findings.

```{r}
# checking for outliers
# load tidy verse
library(tidyverse)

num <- select_if(supermarket, is.numeric)# selecting numerical columns only
boxplot(num,
        main = "Outliers in Numerical Columns",
        xlab = "Columns",
        col = "maroon",
        border = "pink")
```


There are some outliers on cogs,Total column,Tax and Ratings.

The outliers are found in the third quartile,implying they are found in the higher ranges of the variables.

The outliers will not be removed as they may give us more information.


```{r}
# Tax and gross income columns seem to have the same values 
# Let's confirm this
all(supermarket$tax == supermarket$gross.income)
```

The two columns have equal values.

- Gross income includes all income you receive that isn't explicitly exempt from taxation. 

- Taxable income is the portion of your gross income that's actually subject to taxation.

- We can see from the data that the tax column is important because when we add our tax to the cost of goods sold (i.e. the cogs column), we get the final price shown in the Total column. The gross income column is another name for the total column.

- We will therefore drop the gross income column.

```{r}
# Removing gross income column
supermarket <- supermarket[-c(14)]
```


```{r}
# Lets check the columns
names(supermarket)

# gross income has been removed
```


```{r}
# checking to see if our variables have been converted
str(supermarket)
```

# EDA

### UNIVARIATE ANALYSIS

When using univariate approaches, you just look at one variable at a time.

The following are examples of univariate analysis:

- Mean, Median, and Mode are three measures of central tendancy.

- Dispersion measures include the minimum, maximum, range, quartiles, variance, and standard deviation.

- Other factors to consider are skewness and kurtosis.

- Histogram, Box plots, Bar plots, and Kernel density plots are examples of univariate graphs.

```{r}
# convert column product line to a factor
supermarket$product.line <- as.factor(supermarket$product.line)
# convert the other character to facors
supermarket$branch <- as.factor(supermarket$branch)
supermarket$customer.type <- as.factor(supermarket$customer.type)
supermarket$gender <- as.factor(supermarket$gender)
supermarket$payment <- as.factor(supermarket$payment)
```


```{r}
# rename factors so they can fit in barchart
# We will rename:
# Electronic accessories <- EA
# Fashion Accessories <- FA
# Food and Beverage <- FB
# Health and Beauty <- HB
# Home and lifestyle <- HL
# Sports and travel <- ST
levels(supermarket$product.line) <- c("EA","FA","FB","HB","HL","ST")

```



```{r}
# Using the method describe() gives more measures of dispersion
# describe columns
library(psych)
describe(supermarket)
```

```{r}
# Create histogram for our categorical variable
for(i in 2:5){
  counts <- table(supermarket[,i])
  names <- names(supermarket)[i]
  barplot(counts,main = names,col = heat.colors(20))
}
```


```{r}
supermarket %>%
  select(branch,customer.type,gender,product.line,payment) %>%
  summary()
```


- The column branch has three different values(A,B,C)

- There are two categories of customers, as shown by the two distinct values for customer type(Member,Normal).

- Member clients made up 50.1% of the total, while Normal consumers made up 49.9%.

- There are two types of genders. The majority of the clients were of gender Female (50.1%), with the remaining customers being of gender Male(49.9%).

- There are six separate features in the product line(**Electronic accessories,Fashion accesories,Food and beverages,Home and lifestyle,Health and beauty,Sports and travel**), with Fashion accessories having 17.8% more values.

- The cheapest unit cost 10.08, while the most expensive was 99.96.

- The payment mechanism comprised three separate features(**Cash,Credit card,Ewallet**), with feature Ewallet accounting for 34.5% of all transactions.

### Bivariate Analysis

Two variables are analyzed to see if there is a relationship between them.

```{r}
# Let's plot scatter plots
plot(unit.price~ tax, dat = supermarket, 
     col = "blue",
     main = "Unit price vs Tax")
```
As the unit price increases the tax increases this shows a positve linear relationship.

```{r}
# convert column product line to a factor
supermarket$product.line <- as.factor(supermarket$product.line)
```

```{r}
# rename factors so they can fit in barchart
# We will rename:
# Electronic accessories <- EA
# Fashion Accessories <- FA
# Food and Beverage <- FB
# Health and Beauty <- HB
# Home and lifestyle <- HL
# Sports and travel <- ST
levels(supermarket$product.line) <- c("EA","FA","FB","HB","HL","ST")
```

```{r}
# Create a stacked bar chart showing relationship between gender and productline
counts <- table(supermarket$gender,supermarket$product.line)
barplot(counts,
        main= "Bar chart showing gender by product line",
        xlab = "product line",
        ylab = "Frequency",
        col = c("cyan","green"),
        legend = rownames(counts),
        beside = TRUE)
```

- Fashion accessories are the most popular item.

- When compared to other products, fashion accessories are purchased by the majority of women.

- When it comes to health and beauty items, males are more likely to buy than women.


```{r}
# create a chart showing gender vs customer type
library(tidyverse)

supermarket %>% 
    group_by(customer.type) %>% 
    count(gender) %>% 
    mutate(prop = n/sum(n)) %>% 
    ggplot(aes(x = customer.type, y = prop)) +
    geom_col(aes(fill = gender), position = "dodge") +
    geom_text(aes(label = scales::percent(prop), 
                  y = prop, 
                  group = gender),
              position = position_dodge(width = 0.9),
              vjust = 1.5)
```


- The majority of ladies are members by 52.1%, whilst the majority of males are regular clients by 51.9%.

```{r}
# Create a stacked bar chart showing relationship between product line and payment type
supermarket %>% 
    group_by(product.line) %>% 
    count(payment) %>% 
    mutate(prop = n/sum(n)) %>% 
    ggplot(aes(x = product.line, y = prop)) +
    geom_col(aes(fill = payment), position = "dodge") +
    geom_text(aes(label = scales::percent(prop), 
                  y = prop, 
                  group = payment),
              position = position_dodge(width = 0.9),
              vjust = 1.5)
```

- For the Electronic accessories we can see that most customers pay via cash by 41.765% and Sports and travel by 35.542%.

- Ewallet is mostly used in the purchase of fashion accessories(36.517%) and Health and lifestyle products(40%).

- Credit cards are mostly used in the purchase of food and beverages by 35.057%.

```{r}
# checking for correlation of our variables
data.num<-select_if(supermarket,is.numeric)
data.num
data.cor = cor(data.num)
library(corrplot)
corrplot(data.cor, type = 'lower')
```


We change some of the columns with the character datatype to numerical datatype

```{r}
supermarket$branch <- as.integer(as.factor(supermarket$branch))
supermarket$customer.type <- as.integer(as.factor(supermarket$customer.type))
supermarket$gender <- as.integer(as.factor(supermarket$gender))
supermarket$product.line <-as.integer(as.factor(supermarket$product.line))
supermarket$payment <-as.integer(as.factor(supermarket$payment))
```


### PCA

Let's select numerical variables

```{r}
head(supermarket)
```


```{r}
# Importing the library dplyr
library(dplyr)
df <- select_if(supermarket, is.numeric)
```

```{r}
head(df)
```

```{r}
df <- df[,c(-1,-2,-3,-4,-8,-10)]
head(df)
```

We removed the categorical columns as well as the gross.margin.percentage column because it has a constant value throughout for all the rows.

```{r}
# passing df to the prcomp()
# set two arguments, center and scale,to be TRUE then preview our object with summary

super.pca <- prcomp(df, center = TRUE, scale. = T)
summary(super.pca)
```

We have obtained 6 principal components.

PC1 explains 65% of the total variance and PC2 ~17% of the variance.

```{r}
# let's have a look at the PCA object
str(super.pca)
```


```{r}
# Let's plot our pca
# Installing our ggbiplot visualisation package
# 
library(devtools)
install_github("vqv/ggbiplot")
```

```{r}
# Then Loading our ggbiplot library
#  
library(ggbiplot)
ggbiplot(super.pca)

```

```{r}
# Adding more detail to the plot, we provide arguments rownames as labels
# 
ggbiplot(super.pca, labels=rownames(supermarket), obs.scale = 1, var.scale = 1)
```

This plot is not really visually explainable.

Having performed PCA using this dataset, if we were to build a classification model 
the rating,unit price,quantity and cogs would be significant variables as seen in our PCA analysis.

## Feature Selection

```{r}
# reload our dataset
super<- read.csv('http://bit.ly/CarreFourDataset')
head(super)
```

```{r}
# lower case of the column names
names(super) <- tolower(names(super))
names(super)
```


```{r}
# changing data types
super$branch <- as.integer(as.factor(super$branch))
super$customer.type <- as.integer(as.factor(super$customer.type))
super$gender <- as.integer(as.factor(super$gender))
super$product.line <-as.integer(as.factor(super$product.line))
super$payment <-as.integer(as.factor(super$payment))
```


```{r}
# subsetting our data excluding some variables
super_f <- subset( super, select = -c(`invoice.id`  , date, time,`gross.margin.percentage`))
names(super_f)
```

```{r}
# Loading our libraries
library(caret)
library(corrplot)
```

```{r}
# Calculating the correlation matrix
correlationMatrix <- cor(super_f)
```


```{r}
# Find attributes that are highly correlated
highlyCorrelated <- findCorrelation(correlationMatrix, cutoff=0.75)

```


```{r}
# Highly correlated attributes
highlyCorrelated

names(super_f[,highlyCorrelated])
```

Cogs,total and tax have a high correlation to each other.

```{r}
# removing the variables with a higher correlation 
# and comparing the results graphically 

# Removing Redundant Features 

Dataset <-super_f[-highlyCorrelated]
```

```{r}
# our graphical comparison
par(mfrow = c(1, 2))
corrplot(correlationMatrix, order = "hclust")
corrplot(cor(Dataset), order = "hclust")
```

We have removed irrelevant and unnecessary variables.